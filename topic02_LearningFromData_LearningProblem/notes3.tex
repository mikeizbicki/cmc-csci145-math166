\documentclass[10pt]{exam}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{stmaryrd}

\usepackage{color}
\usepackage{colortbl}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{gray}{rgb}{0.7,0.7,0.7}

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = black, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor    = blue  %Colour of citations
}

\usepackage{listings}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\newtheorem{defn}{Definition}
\newtheorem{note}{Note}
\newtheorem{refr}{References}
\newtheorem{theorem}{Theorem}
\newcommand{\E}{\mathbb E}
\newcommand{\R}{\mathbb R}
\DeclareMathOperator{\nnz}{nnz}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\determinant}{det}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\prob}{\mathbb P}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\Ein}{E_{\text{in}}}
\newcommand{\Eout}{E_{\text{out}}}
\newcommand{\Etest}{E_{\text{test}}}
\newcommand{\I}{\mathbf I}
\newcommand{\Q}{\mathbf Q}
\newcommand{\p}{\mathbf P}
\newcommand{\pb}{\bar {\p}}
\newcommand{\pbb}{\bar {\pb}}
\newcommand{\pr}{\bm \pi}

\newcommand{\trans}[1]{{#1}^{T}}
\newcommand{\loss}{\ell}
\newcommand{\w}{\mathbf w}
\newcommand{\wstar}{{\w}^{*}}
\newcommand{\x}{\mathbf x}
\newcommand{\y}{\mathbf y}
\newcommand{\lone}[1]{{\lVert {#1} \rVert}_1}
\newcommand{\ltwo}[1]{{\lVert {#1} \rVert}_2}
\newcommand{\lp}[1]{{\lVert {#1} \rVert}_p}
\newcommand{\linf}[1]{{\lVert {#1} \rVert}_\infty}
\newcommand{\lF}[1]{{\lVert {#1} \rVert}_F}

\newcommand{\HH}[1]{\mathcal H_{\text{#1}}}
\newcommand{\Hbinary}{\HH_{\text{binary}}}
\newcommand{\Haxis}{\HH_{\text{axis}}}
\newcommand{\Hperceptron}{\HH_{\text{perceptron}}}


\newcommand{\ignore}[1]{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}


\begin{center}
{
\Huge
%Chapter 1/2: The Learning Problem (III)
Between Chapters 1 and 2
}
\end{center}

\begin{center}
%\includegraphics[height=3in]{scooby}
%~~~~~~~~~~
%\includegraphics[height=3in]{ml}
\end{center}

\noindent
Chapter 2 of the textbook starts discussing the statistical properties of learning algorithms.
Unfortunately, the textbook material jumps in difficulty a LOT between chapters 1 and 2.
The purpose of these notes is to help ``fill the gap.''
In particular, the textbook introduces the idea of \emph{generalization bounds} and \emph{infinite hypothesis classes} in chapter 2.
Infinite hypothesis classes are fairly abstract and can be a bit tricky to understand.
This set of notes introduces generalization bounds for \emph{finite hypothesis classes},
which are more concrete and easier to understand.

%\section{PAC Learning}

%The goal of PAC learning bounds is to help us choose which model to use for a particular problem.
%(Recall that a model is a hypothesis class plus a learning algorithm.)
%In these notes, we will explore some simple, finite hypothesis classes and the simple TEA learning algorithm.

\begin{problem}
    For each hypothesis class below, draw a picture of what a ``typical'' hypothesis looks like and write the number of elements $M$ in the hypothesis class.
\begin{align*}
    \HH{binary} &= \bigg\{ \x \mapsto +1, \x \mapsto -1 \bigg\}\\
    \vspace{3in}
    \\ \\ \\ \\ \\ \\ \\ \\
    \HH{axis} &= \bigg\{ \x \mapsto \sign(x_i) : i \in [d] \bigg\} \\
    \vspace{3in}
    \\ \\ \\ \\ \\ \\ \\ \\
    \HH{axis2} &= \bigg\{ \x \mapsto \sigma\sign(x_i) : \sigma \in\{+1, -1\}, i \in [d] \bigg\} \\
    \vspace{3in}
\end{align*}
    \begin{align*}
    %\HH{axis3} &= \bigg\{ \x \mapsto \sigma\sign(x_i) : \sigma \in\{+1, 0, -1\}, i \in [d] \bigg\} \\
    %\HH{multiaxis2} &= \bigg\{ \x \mapsto \sum_{j=1}^d \sigma_j \sign(x_j) : \mathbf \sigma \in \{+1, -1\}^d \bigg\}  \\
    \HH{multiaxis2} &= \bigg\{ \x \mapsto \sign\bigg(\sum_{j=1}^d \sigma_j \sign(x_j) \bigg) : \sigma_i \in \{+1, -1\}, i \in [d] \bigg\}  \\
    \\ \\ \\ \\ \\ \\ \\ \\
    \\ \\ \\ \\ \\ \\ \\ \\
    \HH{multiaxis3} &= \bigg\{ \x \mapsto \sign\bigg(\sum_{j=1}^d \sigma_j \sign(x_j) \bigg): \sigma_i \in \{+1, 0, -1\}, i \in [d] \bigg\}  \\
    %\HH{L2-4} &= \bigg\{ \x \mapsto \big\llbracket\ltwo{\x} \ge \alpha \big\rrbracket: \alpha \in \{1, 2, 3, 4\} \bigg\}\\
    %\HH{L1-4} &= \bigg\{ \x \mapsto \big\llbracket \lone{\x} \ge \alpha \big\rrbracket: \alpha \in \{1, 2, 3, 4\} \bigg\}\\
    %\HH{Lp-a} &= \bigg\{ \x \mapsto \big\llbracket \lp{\x} \ge \alpha \big\rrbracket: \alpha \in [a] \bigg\}\\
    %\HH{Lp-a-double} &= \bigg\{ \x \mapsto \sigma\big\llbracket \lp{\x} \ge \alpha \big\rrbracket: \alpha \in [a], \sigma \in \{+1, -1\} \bigg\}\\
\end{align*}
\end{problem}

\newpage
\begin{problem}
    One simple idea for selecting a hypothesis in the hypothesis class is to select the best hypothesis on the training data.
    That is, select
    \begin{equation}
        \label{eq:g}
        g = \argmin_{h\in\mathcal H} \Ein(h)
        .
    \end{equation}
    The \emph{Try Everything Algorithm} (TEA) is a simple algorithm for computing Formula \ref{eq:g} above.
    The pseudo-code is shown below:
    \begin{lstlisting}
    g = None
    g_score = -infinity
    for h in H:
        h_score = E_in(h)
        if h_score > g_score:
            g = h
            g_score = h_score
    \end{lstlisting}
    %What is the runtime of the ERM of the hypothesis classes above?
    What is the runtime of the TEA algorithm?
\end{problem}

\vspace{3in}
\begin{problem}
    Why does it not make sense to run the TEA algorithm on the perceptron hypothesis class?

    HINT: This problem is ``trivial'' in the sense that it follows immediately from definitions and the runtime bound above.
\end{problem}

\newpage
\noindent
%Equation (2.1) in the textbook states the following theorem.
%Page 40 in the textbook defines the following terms and equations.

%\begin{defn}
    %Recall that the \emph{generalization error} of a hypothesis $g$ is defined to be
    %$|\Ein(g) - \Eout(g)|$.
%\end{defn}

\begin{theorem}[Finite Hypothesis Class Generalization]
    %Equation (1.6) in the textbook states that for any hypothesis class $\mathcal H$ with $M$ entries
    Let $\mathcal H$ be a hypothesis class of size $M$,
    let $g$ be an arbitrary hypothesis in $\mathcal H$
    (in particular, $g$ is allowed to be the result of the TEA algorithm),
    and let $N$ be the size of the dataset.
    Then we have that for all $\epsilon>0$,
    \begin{equation*}
    \prob[|\Ein(g) - \Eout(g)| \ge \epsilon] \le 2M\exp(-2\epsilon^2 N).
    \end{equation*}
    This implies that with probability at least $1-\delta$,
    \begin{equation*}
        \Eout(g) \le \Ein(g) + \sqrt{\frac{1}{2N} \log\frac{2M}{\delta}}.
    \end{equation*}
\end{theorem}
%\begin{proof}
\noindent
    \emph{Proof on pages 40-41 of the textbook.  It is an immediate consequence of the Hoeffding inequality and the union bound.  Observe the similarities/differences between the equations above and the Hoeffding inequality; this should help you memorize both results.}
%\end{proof}

\vspace{3in}
\begin{problem}
    Graph the in-sample error, out-of-sample error, and the generalization error as a function of the hypothesis class size $M$.

    This should be done informally/at an ``intuition level''; the next two problems explore these trade-offs more formally.
    This is very similar to Figure 2.3 on page 59 of the textbook.
\end{problem}

\newpage
\begin{problem}
    You have a dataset with 100 dimensions and 500 data points.
    Due to the small amount of training data, you have decided not to split the dataset into training and testing datasets,
    and instead you will use the entire dataset for training.
    Your particular application requires that your final model have a generalization error less than 0.1 with probability at least 0.99.
    \begin{enumerate}
        \item
    Which of the finite hypothesis classes are guaranteed to meet your generalization requirements according to the FHCG Theorem?

            \vspace{4in}
\item
    Of the hypothesis classes that you CAN select, which one SHOULD you select?
    \end{enumerate}

    %You have used the TEA algorithm with the $\HH{multiaxis2}$ hypothesis class on a dataset with 10 dimensions and 10 training points.
\end{problem}

%\begin{theorem}[Union Bound]
    %For any set of events $\mathcal B_1, ..., \mathcal B_n$,
    %we have that
    %\begin{equation}
        %\prob\left(\bigcup_{i=1}^n \mathcal B_i\right)
        %\le
        %\sum_{i=1}^n \prob(\mathcal B_i)
        %.
    %\end{equation}
%\end{theorem}

\newpage
\begin{problem}
    Given two finite hypothesis classes $\HH{1}$ and $\HH{2}$, we can construct a third hypothesis class
    \begin{equation}
        \HH{3} = \HH{1} \cup \HH{2}.
    \end{equation}
    \begin{enumerate}
        \item
            Let $g_i$ be the result of the TEA algorithm on hypothesis class $\HH{i}$.
            How does the in-sample error of $g_3$ compare to the in-sample errors of $g_1$ and $g_2$?
        %How does the training error for $\HH{3}$ compare to the training errors of $\HH{1}$ and $\HH{2}$.

            \vspace{4in}
        \item
            How does the bound on the generalization error from the FHCG theorem for $\HH{3}$ compare to the generalization error of $\HH{1}$ and $\HH{2}$?
    \end{enumerate}
\end{problem}

\newpage
\begin{problem}
    Recall that the Perceptron hypothesis class is defined as
    \begin{equation}
        %\Hperceptron
        %\Hperceptron = 
        \HH{perceptron} = 
        \bigg\{ \x \mapsto \sign(\trans\w \x) : \w \in \R^d \bigg\}.
    \end{equation}
    In practice, computers cannot efficiently implement arbitrary precision real number arithmetic,
    and so all perceptron implementations use a finite precision approximation.%
    \footnote{
    Python (and most other programming languages) natively use 64bit IEEE754 floating point numbers.
    Modern CPUs have native support for 32 bit floating numbers as well,
    and they are often used in numeric computations because they are about twice as fast because there are half as many bits that need to be computed.
    Recently, NVIDIA has begun supporting 16bit, 8bit, and even 4bit floating point numbers.
    These "low precision reals" are most commonly used to speed up computations or reduce memory requirements,
    but this problem shows that these low precision reals can also result in statistical improvements in the generalization error.
    The use of low precision floating point numbers is often called \emph{quantization}.
    }
    Let $b$ be the total number of bits of precision used to represent a real number.

    \begin{enumerate}
        \item
    Write a generalization bound for the finite precision version of the perceptron in terms of $b$, $d$, and $N$.

    \item
        \vspace{3in}
        Based on your bound above, if you double the bits of precision $b$, how much more data $N$ will you need to achieve the same generalization error?

            %\vspace{4in}
            %\newpage
    %\item
        %Assume the data is linearly separable, so that the PLA is guaranteed to converge.
        %Under what conditions will the TEA algorithm be faster for learning a finite precision perceptron model than the PLA?
    \end{enumerate}

\end{problem}


%\newpage
%\section{Practical Problems}
%\begin{problem}
    %You are working on a project for a major streaming service WEBFILMS.
    %WEBFILMS has customers in most countries around the world,
    %Your task 
%\end{problem}

\newpage
\begin{problem}
    Dimensionality reduction is a common technique for improving the computational and statistical performance of an algorithm.
    One simple form of dimensionality reduction is to multiply all the datapoints by a random matrix.
    Formally, let $A : d' \times d$ be a random matrix where each entry is sampled from the uniform distribution on $[-1, 1]$.
    Then each new data point $\x'$ is the $d'$ dimensional vector defined to be
    \begin{equation}
        \x' = A\x.
        %\x' = \frac{A\x}{\sqrt d}.
    \end{equation}
    %The $\sqrt{d}$ in the denominator ensures that $\ltwo{\x'} \approx \ltwo{\x}$.
    %(The norm of the data doesn't affect any of the algorithms we've seen so far,
    %but it is still good practice to keep the norm the same.)

\begin{enumerate}
\item
Complete the table below describing the effect of this transform on the runtime and generalization error of our finite hypothesis classes.

        \vspace{-0.3in}
\renewcommand{\arraystretch}{5}
\begin{tabular}{p{2in}p{2in}p{2in}}
    hypothesis class & runtime of TEA & generalization error \\
    \hline
    $\HH{binary}$ \\
    $\HH{axis}$ \\
    $\HH{axis2}$ \\
    $\HH{multiaxis2}$ \\
    $\HH{multiaxis3}$ \\
    \hline
\end{tabular}

\vspace{0.2in}
\item
Above, you should see either a linear or exponential improvement in all cases.
Why does it not make sense to always perform this dimensionality reduction with a very small $d'$?
(That is, what important quantity not shown in the table above will get worse as $d'$ gets smaller?)
\end{enumerate}
\end{problem}

%\newpage
%\begin{problem}
    %WEBFILMS is a major movie streaming service.
    %They have customers in over one hundred countries,
    %and serve content in over one hundred languages.
    %One of the challenges that WEBFILMS faces is selecting which language settings to use when a customer decides to watch a movie.
%\end{problem}


\end{document}



